# Run MarginPolish and HELEN using local installation
`MarginPolish` requires a draft assembly and a mapping of reads to the draft assembly. We commend using `Shasta` as the initial assembler and `MiniMap2` for the mapping.

#### Step 1: Generate an initial assembly
Although any assembler can be used to generate the initial assembly, we highly recommend using [Shasta](https://github.com/chanzuckerberg/shasta).

Please see the [quick start documentation](https://chanzuckerberg.github.io/shasta/QuickStart.html) to see how to use Shasta. Shasta requires memory intensive computing.
> For a human size assembly, AWS instance type x1.32xlarge is recommended. It is usually available at a cost around $4/hour on the AWS spot market and should complete the human size assembly in a few hours, at coverage around 60x.

An assembly can be generated by running:
```bash
# you may need to convert the fastq to a fasta file
./shasta-Linux-0.1.0 --input <reads.fa> --output <path_to_shasta_output>
```

#### Step 2: Create an alignment between reads and shasta assembly
We recommend using `MiniMap2` to generate the mapping between the reads and the assembly.
```bash
# we recommend using FASTQ as marginPolish uses quality values
# This command can run MiniMap2 with 32 threads, you can change the number as you like.
minimap2 -ax map-ont -t 32 shasta_assembly.fa reads.fq | samtools sort -@ 32 | samtools view -hb -F 0x104 > reads_2_assembly.bam
samtools index -@32 reads_2_assembly.bam

#  the -F 0x104 flag removes unaligned and secondary sequences
```
#### Step 3: Generate images using MarginPolish
To generate images with `MarginPolish` please run:
```bash
cd <path/to/marginPolish/build/>

./marginPolish \
</path/to/reads_2_assembly.bam> \
<path/to/shasta_assembly.fa> \
<path/to/marginpolish/params/allParams.np.human.guppy-ff-235.json> \
-t <number_of_threads> \
-o </path/to/marginpolish_output/marginpolish_images> \
-f 2>&1 | tee </path/to/marginpolish.log>
```

#### Step 4: Run HELEN

##### Download Model
Before running `call_consensus.py` please download the appropriate model suitable for your data. Please read our [model guideline](#Model) to understand which model to pick.

##### Run call_consensus.py
First we have to run `call_consensus.py` to generate all the predictions:
```bash
cd <path/to/helen/>

Example Usage:

python3 call_consensus.py \
-i </path/to/marginpolish_output/marginpolish_images> \
-b <batch_size> \
-w <number_of_workers> \
-t <number_of_threads> \
-m <path/to/helen_models/HELEN_vXXX.pkl> \
-o <path/to/helen_out/consensus_sequence/> \
-g

Arguments:
  -i IMAGE_FILE, --image_file IMAGE_FILE
                        [REQUIRED] Path to a directory where all MarginPolish
                        generated images are.
  -m MODEL_PATH, --model_path MODEL_PATH
                        [REQUIRED] Path to a trained model (pkl file). Please
                        see our github page to see options.
  -b BATCH_SIZE, --batch_size BATCH_SIZE
                        Batch size for testing, default is 512. Please set to
                        512 or 1024 for a balanced execution time.
  -w NUM_WORKERS, --num_workers NUM_WORKERS
                        Number of workers to assign to the dataloader. Can be
                        inferred as min(8, number_of_gpus * 4)
  -t THREADS, --threads THREADS
                        Number of PyTorch threads to use, default is 1. This
                        is helpful during CPU-only inference.
  -o OUTPUT_DIR, --output_dir OUTPUT_DIR
                        Path to the output directory.
  -g, --gpu_mode        If set then PyTorch will use GPUs for inference.

```

##### Run stitch.py
Finally you can run `stitch.py` to get a consensus sequence:
```bash
python3 stitch.py \
-i <path/to/input/hdf_file> \
-o <path/to/output/directory> \
-p <output_file_prefix> \
-t <number_of_threads>


Arguments:
  -i INPUT_HDF, --input_hdf INPUT_HDF
                        [REQUIRED] Path to a HDF5 file that was generated
                        using call consensus.
  -o OUTPUT_DIR, --output_dir OUTPUT_DIR
                        [REQUIRED] Path to the output directory.
  -t THREADS, --threads THREADS
                        [REQUIRED] Number of threads.
  -p OUTPUT_PREFIX, --output_prefix OUTPUT_PREFIX
                        Prefix for the output file. Default is: HELEN_consensus

```

<b>NOTE: We are working on a documentation with instructions for running this pipeline end-to-end.  </b>

## Models
#### Released models
Change in the basecaller algorithm can directly affect the outcome of HELEN. We will release trained models with new basecallers as they come out.
<center>

<table>
  <tr>
    <th>Model Name</th>
    <th>Release Date</th>
    <th>Intended base-caller</th>
    <th>Link</th>
    <th>Comment</th>
  </tr>
  <tr>
    <td>r941_flip231_v001.pkl</td>
    <td>29/05/2019</td>
    <td>Guppy 2.3.1</td>
    <td><a href="https://storage.googleapis.com/kishwar-helen/helen_trained_models/v0.0.1/r941_flip231_v001.pkl">Model_link</a></td>
    <td>The model is trained on chr1-6 of CHM13 <br>with Guppy 2.3.1 base called data.</td>
  </tr>
  <tr>
    <td>r941_flip233_v001.pkl</td>
    <td>29/05/2019</td>
    <td>Guppy 2.3.3</td>
    <td><a href="https://storage.googleapis.com/kishwar-helen/helen_trained_models/v0.0.1/r941_flip233_v001.pkl">Model_link</a></td>
    <td>The model is trained on autosomes of HG002 except <br>chr 20 with Guppy 2.3.3 base called data.</td>
  </tr>
  <tr>
    <td>r941_flip235_v001.pkl</td>
    <td>29/05/2019</td>
    <td>Guppy 2.3.5</td>
    <td><a href="https://storage.googleapis.com/kishwar-helen/helen_trained_models/v0.0.1/r941_flip235_v001.pkl">Model_link</a></td>
    <td>The model is trained on autosomes of HG002 except <br>chr 20 with Guppy 2.3.5 base called data.</td>
  </tr>
</table>
</center>
