import sys
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from modules.python.models.dataloader_predict import SequenceDataset
from modules.python.TextColor import TextColor
from tqdm import tqdm
import numpy as np
from modules.python.models.ModelHander import ModelHandler
from modules.python.Options import ImageSizeOptions, TrainOptions
from modules.python.DataStore import DataStore
"""
This script implements the predict method that is used by the call consensus method.

The algorithm is described here:

  1) INPUTS:
    - directory path to the image files generated by MarginPolish
    - model path directing to a trained model
    - batch size for minibatch prediction
    - num workers for minibatch processing threads
    - output directory path to where the output hdf5 will be saved
    - gpu mode indicating if GPU will be used
  2) METHOD:
    - Call predict function that loads the neural network and generates base predictions and saves it into a hdf5 file
        - Loads the model
        - Iterates over the input images in minibatch
        - For each image uses a sliding window method to slide of the image sequence
        - Aggregate the predictions to get sequence prediction for the entire image sequence
        - Save all the predictions to a file
  3) OUTPUT:
    - A hdf5 file containing all the base predictions   
"""


def predict(test_file, output_filename, model_path, batch_size, num_workers, gpu_mode):
    """
    The predict method loads images generated by MarginPolish and produces base predictions using a
    sequence transduction model based deep neural network. This method loads the model and iterates over
    minibatch images to generate the predictions and saves the predictions to a hdf5 file.

    :param test_file: File to predict on
    :param output_filename: Name and path to the output file
    :param batch_size: Batch size used for minibatch prediction
    :param model_path: Path to a trained model
    :param gpu_mode: If true, predictions will be done over GPU
    :param num_workers: Number of workers to be used by the dataloader
    :return: Prediction dictionary
    """
    # create the output hdf5 file where all the predictions will be saved
    prediction_data_file = DataStore(output_filename, mode='w')

    # notify that the process has started and loading data
    sys.stderr.write(TextColor.PURPLE + 'Loading data\n' + TextColor.END)

    # create a pytorch dataset and dataloader that loads the data in mini_batches
    test_data = SequenceDataset(test_file)
    test_loader = DataLoader(test_data,
                             batch_size=batch_size,
                             shuffle=False,
                             num_workers=num_workers)

    # load the model using the model path
    transducer_model, hidden_size, gru_layers, prev_ite = \
        ModelHandler.load_simple_model(model_path,
                                       input_channels=ImageSizeOptions.IMAGE_CHANNELS,
                                       image_features=ImageSizeOptions.IMAGE_HEIGHT,
                                       seq_len=ImageSizeOptions.SEQ_LENGTH,
                                       num_base_classes=ImageSizeOptions.TOTAL_BASE_LABELS,
                                       num_rle_classes=ImageSizeOptions.TOTAL_RLE_LABELS)

    # set the model to evaluation mode.
    transducer_model.eval()

    # if gpu mode is True, then load the model in the GPUs
    if gpu_mode:
        transducer_model = torch.nn.DataParallel(transducer_model).cuda()

    # notify that the model has loaded successfully
    sys.stderr.write(TextColor.CYAN + 'MODEL LOADED\n')

    # iterate over the data in minibatches
    with torch.no_grad():
        # the dataloader loop, iterates in minibatches. tqdm is the progress logger.
        for contig, contig_start, contig_end, chunk_id, images, position, filename in tqdm(test_loader, ncols=50):
            # the images are usually in uint8, convert them to FloatTensor
            images = images.type(torch.FloatTensor)
            # initialize the first hidden input as all zeros
            hidden = torch.zeros(images.size(0), 2 * TrainOptions.GRU_LAYERS, TrainOptions.HIDDEN_SIZE)

            # if gpu_mode is True, transfer the image and hidden tensors to the GPU
            if gpu_mode:
                images = images.cuda()
                hidden = hidden.cuda()

            # this is a multi-task neural network where we predict a base and a run-length. We use two dictionaries
            # to keep track of predictions.
            # these two dictionaries save predictions for each of the chunks and later we aggregate all the predictions
            # over the entire sequence to get a sequence prediction for the whole sequence.
            prediction_base_dict = np.zeros((images.size(0), images.size(1), ImageSizeOptions.TOTAL_BASE_LABELS))
            prediction_rle_dict = np.zeros((images.size(0), images.size(1), ImageSizeOptions.TOTAL_RLE_LABELS))

            # now the images usually contain 1000 bases, we iterate on a sliding window basis where we process
            # the window size then jump to the next window
            for i in range(0, ImageSizeOptions.SEQ_LENGTH, TrainOptions.WINDOW_JUMP):
                # if current position + window size goes beyond the size of the window, that means we've reached the end
                if i + TrainOptions.TRAIN_WINDOW > ImageSizeOptions.SEQ_LENGTH:
                    break
                chunk_start = i
                chunk_end = i + TrainOptions.TRAIN_WINDOW

                # get the image chunk
                image_chunk = images[:, chunk_start:chunk_end]

                # run inference
                output_base, output_rle, hidden = transducer_model(image_chunk, hidden)

                # do softmax and get prediction
                # this can be done on GPU, need to look into this
                m = nn.Softmax(dim=2)
                soft_probs = m(output_base)
                output_preds = soft_probs.cpu()
                # use the maximum probability value as prediction
                base_max_value, predicted_base_label = torch.max(output_preds, dim=2)

                # convert everything to list
                base_max_value = base_max_value.numpy().tolist()
                predicted_base_label = predicted_base_label.numpy().tolist()

                # do softmax and get prediction for rle
                m_rle = nn.Softmax(dim=2)
                rle_soft_probs = m_rle(output_rle)
                rle_output_preds = rle_soft_probs.cpu()
                rle_max_value, predicted_rle_labels = torch.max(rle_output_preds, dim=2)

                # convert everything to list
                rle_max_value = rle_max_value.numpy().tolist()
                predicted_rle_labels = predicted_rle_labels.numpy().tolist()

                # make sure the lengths oof the multi-task predictions are the same
                assert(len(base_max_value) == len(predicted_base_label) == len(predicted_rle_labels))

                # iterate over the images and populate the prediction dictionaries for each chunk
                for ii in range(0, len(predicted_base_label)):
                    chunk_pos = chunk_start
                    for p_base, p_rle, base, rle in zip(base_max_value[ii],
                                                        rle_max_value[ii],
                                                        predicted_base_label[ii],
                                                        predicted_rle_labels[ii]):
                        prediction_base_dict[ii][chunk_pos][base] += p_base
                        prediction_rle_dict[ii][chunk_pos][rle] += p_rle
                        chunk_pos += 1

            # now that we have predictions for each chunk, we can aggregate all the predictions and have
            # one sequence for the entire length of the image sequence.
            predicted_base_labels = np.argmax(np.array(prediction_base_dict), axis=2)
            predicted_rle_labels = np.argmax(np.array(prediction_rle_dict), axis=2)

            # go to each of the images and save the predictions to the file
            for i in range(images.size(0)):
                prediction_data_file.write_prediction(contig[i], contig_start[i], contig_end[i], chunk_id[i],
                                                      position[i], predicted_base_labels[i], predicted_rle_labels[i],
                                                      filename[i])